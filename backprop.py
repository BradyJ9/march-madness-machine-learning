from sklearn.base import BaseEstimator, ClassifierMixinfrom sklearn.neural_network import MLPClassifierimport numpy as npimport matplotlib.pyplot as pltfrom Network import *import mathimport randomclass MLP(BaseEstimator,ClassifierMixin):    def __init__(self,lr=.1, momentum=0, shuffle=True,hidden_layer_widths=None):        """ Initialize class with chosen hyperparameters.        Args:            lr (float): A learning rate / step size.            shuffle(boolean): Whether to shuffle the training data each epoch. DO NOT SHUFFLE for evaluation / debug datasets.            momentum(float): The momentum coefficent         Optional Args (Args we think will make your life easier):            hidden_layer_widths (list(int)): A list of integers which defines the width of each hidden layer if hidden layer is none do twice as many hidden nodes as input nodes. (and then one more for the bias node)            For example: input width 1, then hidden layer will be 3 nodes        Example:            mlp = MLP(lr=.2,momentum=.5,shuffle=False,hidden_layer_widths = [3,3]),  <--- this will create a model with two hidden layers, both 3 nodes wide        """        self.hidden_layer_widths = hidden_layer_widths #if len is 0, then input nodes * 2                          self.lr = lr        self.momentum = momentum        self.shuffle = shuffle            def init_network(self, input_nodes, hidden_layers, hidden_layer_width, output_nodes):        self.network = Network(input_nodes, hidden_layers, hidden_layer_width, output_nodes)          def fit(self, X, y, initial_weights=None, epochs=-1, validation_X=None, validation_y=None, use_validation_set=False): #train        BIAS = 1        INPUT_LAYER = 0        HIDDEN_LAYER = 1        OUTPUT_LAYER = 2                validation_set = None        best_weights = []        """ Fit the data; run the algorithm and adjust the weights to find a good solution        Args:            X (array-like): A 2D numpy array with the training data, excluding targets            y (array-like): A 2D numpy array with the training targets        Optional Args (Args we think will make your life easier):            initial_weights (array-like): allows the user to provide initial weights        Returns:            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)        """        #check null of network        if not self.network:          raise Exception("Cannot fit when Network is null")                self.initialize_weights(initial_weights)        delta_w_m1 = [[None for y in range(self.network.input_layer_nodes)] for x in range(self.network.hidden_layer_nodes - 1)]        for o in range(self.network.output_layer_nodes):          delta_w_m1.append([None for z in range(self.network.hidden_layer_nodes)])                        eval_set_continue = True        best_val_set_accuracy = 0        epochs_since_best_val_set = 0                curr_epoch = 1                if isinstance(y, np.ndarray):          y = y.T.tolist()                while epochs > 0 or (epochs == -1 and eval_set_continue):          #FORWARD PROP          for i in range(len(X)): #instance in an epoch            for h_n in range(len(self.network.layers[HIDDEN_LAYER].nodes) - BIAS):              net = 0              for x in range(self.network.input_layer_nodes):                net += float(X[i][x]) * float(self.network.layers[HIDDEN_LAYER].connected_weights[h_n][x])              self.network.layers[HIDDEN_LAYER].nodes[h_n].net = net              try:                if net > 700:                  net = 700                elif net < -700:                  net = -700                #print("NET: " + str(net))                self.network.layers[HIDDEN_LAYER].nodes[h_n].z_act_fun = 1 / (1 + math.exp(-1 * net))              except OverflowError:                print("NET: " + str(net))                raise OverflowError("math rng err")              for o_n in range(len(self.network.layers[OUTPUT_LAYER].nodes)):              net = 0              for x in range(self.network.hidden_layer_nodes):                if x == self.network.hidden_layer_nodes - BIAS: #then input is 1                  net += 1 * self.network.layers[OUTPUT_LAYER].connected_weights[o_n][x]                else: #then input is z from prev node                  net += self.network.layers[HIDDEN_LAYER].nodes[x].z_act_fun * self.network.layers[OUTPUT_LAYER].connected_weights[o_n][x]              self.network.layers[OUTPUT_LAYER].nodes[o_n].net = net              self.network.layers[OUTPUT_LAYER].nodes[o_n].z_act_fun = 1 / (1 + math.exp(-1 * net))              #Compute Error: Forward Prop            for o_n_e in range(len(self.network.layers[OUTPUT_LAYER].nodes)):              #One hot would be y[o_n_e][i]              if isinstance(y[0], (np.ndarray, list)): #using one-hot                e = (float(y[i][o_n_e]) - self.network.layers[OUTPUT_LAYER].nodes[o_n_e].z_act_fun) * (self.network.layers[OUTPUT_LAYER].nodes[o_n_e].z_act_fun * (1 - self.network.layers[OUTPUT_LAYER].nodes[o_n_e].z_act_fun))              else:                e = (float(y[i]) - self.network.layers[OUTPUT_LAYER].nodes[o_n_e].z_act_fun) * (self.network.layers[OUTPUT_LAYER].nodes[o_n_e].z_act_fun * (1 - self.network.layers[OUTPUT_LAYER].nodes[o_n_e].z_act_fun))              self.network.layers[OUTPUT_LAYER].nodes[o_n_e].error = e                          for h_n_e in range(len(self.network.layers[HIDDEN_LAYER].nodes) - BIAS):              cumulative_error_from_prev= 0              for o in range(len(self.network.layers[OUTPUT_LAYER].nodes)):                cumulative_error_from_prev += self.network.layers[OUTPUT_LAYER].nodes[o].error * self.network.layers[OUTPUT_LAYER].connected_weights[o][h_n_e] * (self.network.layers[HIDDEN_LAYER].nodes[h_n_e].z_act_fun * (1 - self.network.layers[HIDDEN_LAYER].nodes[h_n_e].z_act_fun))              self.network.layers[HIDDEN_LAYER].nodes[h_n_e].error = cumulative_error_from_prev                          #Update Weights : Back Prop                        for h_n_w in range(len(self.network.layers[HIDDEN_LAYER].nodes) - BIAS): #HIDDEN WEIGHTS UPDATE              for w in range(self.network.input_layer_nodes):                momentum = 0                if delta_w_m1[h_n_w][w]: #if exists, first time will be none                  momentum = self.momentum * delta_w_m1[h_n_w][w]                                  delta_w = self.lr * self.network.layers[HIDDEN_LAYER].nodes[h_n_w].error * float(X[i][w]) + momentum                self.network.layers[HIDDEN_LAYER].connected_weights[h_n_w][w] += delta_w                delta_w_m1[h_n_w][w] = delta_w                            for o_n_w in range(len(self.network.layers[OUTPUT_LAYER].nodes)): #OUTPUT WEIGHTS UPDATE              for w in range(self.network.hidden_layer_nodes):                momentum = 0                if delta_w_m1[self.network.hidden_layer_nodes - BIAS + o_n_w][w]:                  momentum = self.momentum * delta_w_m1[self.network.hidden_layer_nodes - BIAS + o_n_w][w]                                  if w == self.network.hidden_layer_nodes - BIAS: #then input is 1     //this is included in the output node weight and not the hidden nodes b/c input/activation of bias weight is included in X data                  z = 1                else:                  z = self.network.layers[HIDDEN_LAYER].nodes[w].z_act_fun                                  delta_w = self.lr * self.network.layers[OUTPUT_LAYER].nodes[o_n_w].error * z + momentum                self.network.layers[OUTPUT_LAYER].connected_weights[o_n_w][w] += delta_w                delta_w_m1[self.network.hidden_layer_nodes - BIAS + o_n_w][w] = delta_w                  #print("Epoch: " + str(curr_epoch))          if epochs != -1: #DET            epochs -= 1          else: #NON-DET, val set            if use_validation_set:               accuracy = self.score(validation_X, validation_y, calc_MSE=True)              if accuracy == 1: #100% accuracy on validation set                #print("\n***Validation Set 100% Accuracy\n")                eval_set_continue = False                 bw = self.network.get_weights()                best_weights = []                for w in range(len(bw)):                  best_weights.append(list(bw[w]))                self.network.init_weights(best_weights)                            elif accuracy > best_val_set_accuracy:                #print("\n********NEW BEST HIT!!!********\n")                best_val_set_accuracy = accuracy                epochs_since_best_val_set = 0                bw = self.network.get_weights()                best_weights = []                for w in range(len(bw)):                  best_weights.append(list(bw[w]))                                else:                epochs_since_best_val_set += 1                if epochs_since_best_val_set >= 10: #stopping criteria, no improvement measured over x epochs,                   #print("\n***No improvement, stopping criteria hit\n")                  eval_set_continue = False                   self.network.init_weights(best_weights)                              else:              raise Exception("Unhandled case...non-det with no validation set...")                    if self.shuffle:            X, y = self._shuffle_data(X, y)            #self.score(X, y, calc_MSE=True)                    curr_epoch += 1                                return self    def predict(self, X):        BIAS = 1        HIDDEN_LAYER = 1        OUTPUT_LAYER = 2        """ Predict all classes for a dataset X        Args:            X (array-like): A 2D numpy array with the training data, excluding targets        Returns:            array, shape (n_samples,)                Predicted target values per element in X.        """        output_y = []        for i in range(len(X)):          for h_n in range(len(self.network.layers[HIDDEN_LAYER].nodes) - BIAS):            net = 0            for x in range(self.network.input_layer_nodes):              net += float(X[i][x]) * self.network.layers[HIDDEN_LAYER].connected_weights[h_n][x]              try:                if net > 700:                  net = 700                elif net < -700:                  net = -700                #print("NET: " + str(net))                self.network.layers[HIDDEN_LAYER].nodes[h_n].z_act_fun = 1 / (1 + math.exp(-1 * net))              except OverflowError:                print("NET: " + str(net))                raise OverflowError("math rng err")            self.network.layers[HIDDEN_LAYER].nodes[h_n].net = net            self.network.layers[HIDDEN_LAYER].nodes[h_n].z_act_fun = 1 / (1 + math.exp(-1 * net))          for o_n in range(len(self.network.layers[OUTPUT_LAYER].nodes)):              net = 0              for x in range(self.network.hidden_layer_nodes):                if x == self.network.hidden_layer_nodes - BIAS: #then input is 1                  net += 1 * self.network.layers[OUTPUT_LAYER].connected_weights[o_n][x]                else: #then input is z from prev node                  net += self.network.layers[HIDDEN_LAYER].nodes[x].z_act_fun * self.network.layers[OUTPUT_LAYER].connected_weights[o_n][x]              new_net = net              new_z = 1 / (1 + math.exp(-1 * net))              self.network.layers[OUTPUT_LAYER].nodes[o_n].net = new_net              self.network.layers[OUTPUT_LAYER].nodes[o_n].z_act_fun = new_z                                if len(self.network.layers[OUTPUT_LAYER].nodes) > 1:  #One Hot Encoding Output            hi_index = 0            for o_n_z in range(len(self.network.layers[OUTPUT_LAYER].nodes)):              #find out which one is largest, that is the 1, the rest are 0s              if self.network.layers[OUTPUT_LAYER].nodes[o_n_z].z_act_fun > self.network.layers[OUTPUT_LAYER].nodes[hi_index].z_act_fun:                hi_index = o_n_z                        output = []            for r in range(len(self.network.layers[OUTPUT_LAYER].nodes)):              if r == hi_index:                output.append(1)              else:                output.append(0)            output_y.append(output)          else:            if self.network.layers[OUTPUT_LAYER].nodes[0].z_act_fun > 0.5:              output = 1            else:              output = 0            output_y.append(output)                return output_y                    def initialize_weights(self, initial_weights):        """ Initialize weights for perceptron. Don't forget the bias!        Returns:        """        if initial_weights:          self.network.init_weights(initial_weights)          return initial_weights        else:          initial_weights_to_hl = np.random.randn(self.network.hidden_layer_nodes - 1, self.network.input_layer_nodes).tolist() #hidden layer nodes - BIAS, input layer nodes          init_weights_to_ol = np.random.randn(self.network.output_layer_nodes, self.network.hidden_layer_nodes).tolist() #output layer nodes, hidden layer nodes          weights_array = []          for h in range(len(initial_weights_to_hl)):            weights_array.append(initial_weights_to_hl[h])          for o in range(len(init_weights_to_ol)):            weights_array.append(init_weights_to_ol[o])          self.network.init_weights(weights_array)          return weights_array          def add_bias(self, data):        return np.insert(data, len(data[0]) - 1, 1, axis=1)    def score(self, X, y, calc_MSE=False):        OUTPUT_LAYER = 2        """ Return accuracy of model on a given dataset. Must implement own score function.        Args:            X (array-like): A 2D numpy array with data, excluding targets            y (array-like): A 2D numpy array with targets        Returns:            score : float                Mean accuracy of self.predict(X) wrt. y.        """        predict_y = self.predict(X)        correct = 0        mse = 0                if len(self.network.layers[OUTPUT_LAYER].nodes) > 1:          for yi in range(len(y)):            all_true = True            for yi_o in range(len(y[yi])):              if calc_MSE:                mse += pow((float(y[yi][yi_o]) - float(predict_y[yi][yi_o])), 2)              if float(y[yi][yi_o]) != float(predict_y[yi][yi_o]):                all_true = False            if all_true:              correct += 1                      else:          for yi in range(len(y)):            if calc_MSE:              mse += pow((float(y[yi]) - float(predict_y[yi])), 2)            if int(y[yi]) == predict_y[yi]:              correct += 1        #print(str(correct) + " correct out of " + str(len(y)) + "..." + str(correct/len(y)) + "%")                if calc_MSE:          mse = mse / len(y)          #print("MSE: " + str(mse))                  return correct/len(y)    def _shuffle_data(self, X, y):        #print(X)        #print(y)        if isinstance(y[0], (np.ndarray, list)): #using one-hot          y_np = np.array(y).T                    y_col = len(y[0])        else:          y_2d = [y]          y_np = np.array(y_2d)          y_col = 1                #print(X)        #print(y_np.T)        catData = np.append(X, y_np.T, axis=1)        #print(catData)                #print("\nSHUFFLING\n")                np.random.shuffle(catData)        #print(catData)                #print("NEW X")        #print(catData[:, :(-1 * y_col)])                #print("NEW Y")        #print(catData[:, (-1 * y_col):])                return catData[:, :(-1 * y_col)], catData[:, (-1 * y_col):]      ### Not required by sk-learn but required by us for grading. Returns the weights.    def get_weights(self):        weights = []        for l in range(len(self.network.layers)):          if self.network.layers[l].connected_weights:            weights.append(self.network.layers[l].connected_weights)                return weights      